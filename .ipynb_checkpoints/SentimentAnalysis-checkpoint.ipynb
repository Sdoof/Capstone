{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "This is to train a classifier on a robust and tagged twitter corpus( obtained from a kaggle challenge ) and allow the model to be used for tagging the scraped tweets  as either 0(negative) or 1(positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                       is so sad for my APL frie...\n",
       "1          0                     I missed the New Moon trail...\n",
       "2          1                            omg its already 7:30 :O\n",
       "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get the dataset.\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = open(\"kaggleTweets.csv\", \"rb\")\n",
    "df = pd.read_csv(data, error_bad_lines=False, usecols=['Sentiment', 'SentimentText'], encoding='utf-8')\n",
    "df = df[:100000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    try:\n",
    "        text = re.sub('<[^>]*>', ' ', text)    # removes HTML from tweets\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        text = re.sub('(http|https)://[^ ]+ ', '', text)    # removes all the hyperlinks\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        text = re.sub('\\s\\s+', '', text)    # removes all the extra whitespaces\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P|[^T_T])', text)    #find all emoticons\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        text = re.sub('[\\W]+', ' ', text.lower()) + ''.join(emoticons).replace('-', '')  # appends emmoticons at the end.\n",
    "    except:\n",
    "        text = text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' quot then jesus said have dinner with me quot and the man responded quot first send me your resume and photo ;a;f'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(df.loc[14000, \"SentimentText\"])    #example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['SentimentText'] = df['SentimentText'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i missed the new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7 30 o:3:O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>omgaga im soooim gunna cry i ve been at this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me t_t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                       is so sad for my apl friend \n",
       "1          0                     i missed the new moon trailer \n",
       "2          1                         omg its already 7 30 o:3:O\n",
       "3          0   omgaga im soooim gunna cry i ve been at this ...\n",
       "4          0                i think mi bf is cheating on me t_t"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processing into tokens\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "#     return [porter.stem(word) for word in text.split()]\n",
    "    for word in text.split():\n",
    "        try:\n",
    "            return porter.stem(word)\n",
    "        except Exception:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'quot',\n",
       " u'then',\n",
       " u'jesu',\n",
       " u'said',\n",
       " u'have',\n",
       " u'dinner',\n",
       " u'with',\n",
       " u'me',\n",
       " u'quot',\n",
       " u'and',\n",
       " u'the',\n",
       " u'man',\n",
       " u'respond',\n",
       " u'quot',\n",
       " u'first',\n",
       " u'send',\n",
       " u'me',\n",
       " u'your',\n",
       " u'resum',\n",
       " u'and',\n",
       " u'photo',\n",
       " u';a;f']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplary run\n",
    "tokenizer_porter(df.loc[14000, \"SentimentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# storing all the stopwords in an array.\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a supervised learning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare dataset to be operated upon by GridSearchCV\n",
    "X_train = df.loc[:50000, \"SentimentText\"].values\n",
    "y_train = df.loc[:50000, \"Sentiment\"].values\n",
    "X_test = df.loc[50000:, \"SentimentText\"].values\n",
    "y_test = df.loc[50000:, \"Sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using GridSearchCV to find best parameters to use for classifier(SGDClassifier)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tru...nalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'vect__ngram_range': [(1, 1)], 'vect__tokenizer': [<function tokenizer at 0x7fe3fb854230>, <function tokenizer_porter at 0x7fe3fb854488>], 'clf__penalty': ['l1', 'l2'], 'clf__C': [1.0, 10.0, 100.0], 'vect__stop_words': [[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves...e3fb854488>], 'vect__use_idf': [False], 'clf__C': [1.0, 10.0, 100.0], 'clf__penalty': ['l1', 'l2']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'vect__ngram_range': (1, 1), 'vect__tokenizer': <function tokenizer at 0x7fe3fb854230>, 'clf__penalty': 'l2', 'clf__C': 1.0, 'vect__stop_words': None} \n",
      "CV Accuracy: 0.735\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: %s '% gs_lr_tfidf.best_params_)\n",
    "print('CV Accuracy: %.3f'%gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.760\n"
     ]
    }
   ],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "serialize the classifier as a pickle file\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('tweetclassifier', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "    \n",
    "# we serialize our stopwords so that we do not have to install NLTK on our servers    \n",
    "pickle.dump(stop,\n",
    "           open(os.path.join(dest, 'stopwords.pkl'), 'wb')\n",
    "           )\n",
    "\n",
    "pickle.dump(clf,\n",
    "            open(os.path.join(dest, 'classifier.pkl'), 'wb')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "clf = pickle.load(open(os.path.join('tweetclassifier' , 'pkl_objects', 'classifier.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n",
      "Probability: 59.83\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "label = {0:'negative', 1:'positive'}\n",
    "\n",
    "# examplery\n",
    "example = ['Drop the beat and go wild.']\n",
    "print('Prediction: {}\\nProbability: {:.2f}'.format(label[clf.predict(example)[0]], clf.predict_proba(example).max()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading classifier and the dataset to be tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Tweets sentiment\n",
      "0  is taking this day to relax and catch up on sl...       NaN\n",
      "1  Went to chiro today...very sore now, but know ...       NaN\n",
      "2  Updated the iPhone 2G to OS 3.0. Feels zippier...       NaN\n",
      "3  I am SOOO hyped for this weekend. Going to Va ...       NaN\n",
      "4  Was feeling down earlier but two wonderful fri...       NaN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "clf = pickle.load(open(os.path.join('tweetclassifier' , 'pkl_objects', 'classifier.pkl'), 'rb'))\n",
    "\n",
    "data = open(\"twitterData.csv\", \"rb\")\n",
    "df = pd.read_csv(data, error_bad_lines=False, usecols=['Tweets', 'sentiment'], encoding='utf-8')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "apply processor to all tweets to get clean data such that prediction can be made on it.\n",
    "'''\n",
    "df['Tweets'] = df['Tweets'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    is taking this day to relax and catch up on sl...\n",
       "1    went to chiro today very sore now but know i w...\n",
       "2    updated the iphone 2g to os 3 0 feels zippier ...\n",
       "3    i am sooo hyped for this weekend going to va f...\n",
       "4    was feeling down earlier but two wonderful fri...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "exemplary testing\n",
    "'''\n",
    "df['Tweets'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is taking this day to relax and catch up on sl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>went to chiro today very sore now but know i w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>updated the iphone 2g to os 3 0 feels zippier ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am sooo hyped for this weekend going to va f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>was feeling down earlier but two wonderful fri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets sentiment\n",
       "0  is taking this day to relax and catch up on sl...       NaN\n",
       "1  went to chiro today very sore now but know i w...       NaN\n",
       "2  updated the iphone 2g to os 3 0 feels zippier ...       NaN\n",
       "3  i am sooo hyped for this weekend going to va f...       NaN\n",
       "4  was feeling down earlier but two wonderful fri...       NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply classifier on tweets and predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5092\n",
      "\n",
      "20802\n",
      "\n",
      "27992\n",
      "\n",
      "48738\n",
      "\n",
      "78397\n",
      "\n",
      "78524\n",
      "\n",
      "80309\n",
      "\n",
      "101148\n",
      "\n",
      "107325\n",
      "\n",
      "109572\n",
      "\n",
      "126462\n",
      "\n",
      "137404\n",
      "\n",
      "140912\n",
      "\n",
      "142019\n",
      "\n",
      "155004\n",
      "\n",
      "164791\n",
      "\n",
      "166199\n",
      "\n",
      "168287\n",
      "\n",
      "169541\n",
      "\n",
      "169796\n",
      "\n",
      "176450\n",
      "\n",
      "178049\n",
      "\n",
      "186489\n",
      "\n",
      "186990\n",
      "\n",
      "187645\n",
      "\n",
      "194024\n",
      "\n",
      "199346\n",
      "\n",
      "202838\n",
      "\n",
      "204161\n",
      "\n",
      "211643\n",
      "\n",
      "215697\n",
      "\n",
      "220241\n",
      "\n",
      "226685\n",
      "\n",
      "230714\n",
      "\n",
      "230789\n",
      "\n",
      "233830\n",
      "\n",
      "240563\n",
      "\n",
      "241102\n",
      "\n",
      "244554\n",
      "\n",
      "244741\n",
      "\n",
      "245161\n",
      "\n",
      "248908\n",
      "\n",
      "249226\n",
      "\n",
      "251753\n",
      "\n",
      "256517\n",
      "\n",
      "256728\n",
      "\n",
      "261710\n",
      "\n",
      "268424\n",
      "\n",
      "274864\n",
      "\n",
      "275269\n",
      "\n",
      "282820\n",
      "\n",
      "284716\n",
      "\n",
      "284767\n",
      "\n",
      "289213\n",
      "\n",
      "291719\n",
      "\n",
      "298847\n",
      "\n",
      "306356\n",
      "\n",
      "309581\n",
      "\n",
      "309647\n",
      "\n",
      "310244\n",
      "\n",
      "310261\n",
      "\n",
      "312130\n",
      "\n",
      "313926\n",
      "\n",
      "314150\n",
      "\n",
      "314405\n",
      "\n",
      "317075\n",
      "\n",
      "318068\n",
      "\n",
      "326584\n",
      "\n",
      "329149\n",
      "\n",
      "336283\n",
      "\n",
      "352413\n",
      "\n",
      "354793\n",
      "\n",
      "355887\n",
      "\n",
      "357052\n",
      "\n",
      "357728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tag the tweets using classifier \n",
    "and print the cases that raise exception.\n",
    "'''\n",
    "\n",
    "for i in range(len(df['Tweets'])):\n",
    "    try:\n",
    "        df['sentiment'][i] = clf.predict([df['Tweets'][i]])[0]\n",
    "    except:\n",
    "        print(\"{}\\n\".format(i))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for tweets on following indices,\n",
    "classifier raised exeptions.\n",
    "'''\n",
    "faulty = [5092,20802,27992,48738,78397,78524,80309,101148,107325,109572,126462,137404,140912,142019,155004,164791,166199,168287,169541,169796,176450,178049,186489,186990,187645,194024,199346,202838,204161,211643,215697,220241,226685,230714,230789,233830,240563,241102,244554,244741,245161,248908,249226,251753,256517,256728,261710,268424,274864,275269,282820,284716,284767,289213,291719,298847,306356,309581,309647,310244,310261,312130,313926,314150,314405,317075,318068,326584,329149,336283,352413,354793,355887,357052,357728]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "make all sentiment None for all faulty tweets.\n",
    "'''\n",
    "for i in faulty:\n",
    "    df['sentiment'][i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is taking this day to relax and catch up on sl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>went to chiro today very sore now but know i w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>updated the iphone 2g to os 3 0 feels zippier ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am sooo hyped for this weekend going to va f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>was feeling down earlier but two wonderful fri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets sentiment\n",
       "0  is taking this day to relax and catch up on sl...         1\n",
       "1  went to chiro today very sore now but know i w...         0\n",
       "2  updated the iphone 2g to os 3 0 feels zippier ...         0\n",
       "3  i am sooo hyped for this weekend going to va f...         1\n",
       "4  was feeling down earlier but two wonderful fri...         1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --------> None\n"
     ]
    }
   ],
   "source": [
    "# exemplary check\n",
    "print(\"{} --------> {}\".format(df.loc[5092,'Tweets'], df.loc[5092,'sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating processed and tagged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "reload the raw dataset file to get a fresh dataframe\n",
    "'''\n",
    "datafile = open(\"twitterData.csv\", \"rb\")\n",
    "new_df = pd.read_csv(datafile, error_bad_lines=False, usecols=['Date', 'Name', 'Tweets', 'sentiment'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "update the old columns with\n",
    "-> new processed tweets,\n",
    "and\n",
    "-> corresponding sentiment.\n",
    "'''\n",
    "new_df['Tweets'] = df['Tweets']\n",
    "new_df['sentiment'] = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "write the dataframe to a new csv file.\n",
    "'''\n",
    "new_df.to_csv('TaggedData.csv', columns=['Date', 'Name', 'Tweets', 'sentiment'], encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
